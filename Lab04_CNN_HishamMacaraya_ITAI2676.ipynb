{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fK46PtzUyabH"
   },
   "source": [
    " Building a CNN for MNIST Handwritten Digit Classification\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Welcome! In this assignment, you will build a Convolutional Neural Network (CNN) to classify handwritten digits from the famous MNIST dataset. This dataset is a classic in the field of computer vision and provides a great starting point for understanding image classification with deep learning.\n",
    "\n",
    "This notebook is structured to guide you step-by-step through the process. You will load the data, preprocess it, define a CNN model, train it, and evaluate its performance.  Throughout the assignment, you will have opportunities to experiment and deepen your understanding of the concepts.\n",
    "\n",
    "Remember to:\n",
    "\n",
    "*   **Read all instructions carefully.**\n",
    "*   **Execute the code cells in order.**\n",
    "*   **Fill in the missing code sections marked as \"Students: Fill in the blanks\".**\n",
    "*   **Answer the reflection questions in the designated Markdown cell.**\n",
    "*   **Experiment and explore!**  Change parameters, layers, and observe the effects.\n",
    "\n",
    "Let's get started and build our MNIST digit classifier!\n",
    "\n",
    "## Section 1: Setting Up - Imports\n",
    "\n",
    "Before we dive into building our CNN, we need to import the necessary libraries.  These libraries provide pre-built tools and functions that will make our work much easier.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1.  **Carefully review the code cell below.** It imports libraries from TensorFlow and Keras, which are powerful frameworks for building and training neural networks.\n",
    "2.  **Execute the code cell by selecting it and pressing [Shift + Enter] (or the \"Run\" button).**\n",
    "3.  **Ensure there are no error messages after running the cell.** If you encounter errors, double-check that you have TensorFlow and Keras installed in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xN_gVhnXyabK"
   },
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXAItJ1RyabL"
   },
   "source": [
    "**Explanation of Imports:**\n",
    "\n",
    "*   **`tensorflow as tf` and `keras`:** TensorFlow is the main deep learning framework, and Keras is its high-level API that simplifies building and training models. We import TensorFlow as `tf` and Keras directly for easy access to their functionalities.\n",
    "*   **`from tensorflow.keras import layers`:**  This imports the `layers` module from Keras, which provides various layers for building neural networks (like convolutional layers, dense layers, etc.).\n",
    "*   **`from tensorflow.keras.datasets import mnist`:**  This imports the MNIST dataset directly from Keras datasets.  This is very convenient for loading and using the MNIST data.\n",
    "*   **`from tensorflow.keras.utils import to_categorical`:**  This imports the `to_categorical` function, which we will use to perform one-hot encoding of our labels.\n",
    "\n",
    "## Section 2: Data Loading and Preprocessing\n",
    "\n",
    "In this section, we will load the MNIST dataset and prepare it for training our CNN model.  Preprocessing steps are crucial to ensure our data is in the right format for the model to learn effectively.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1.  **Read through the code in the cell below.**  Understand how it loads the MNIST dataset and what preprocessing steps are applied.\n",
    "2.  **Execute the code cell.**\n",
    "3.  **Examine the comments in the code** to understand each preprocessing step in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OCi441G0yabL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Data Loading and Preprocessing\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Add a channel dimension (for grayscale images, it's 1)\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# One-hot encode the labels\n",
    "num_classes = 10\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNkWB4hvyabM"
   },
   "source": [
    "**Explanation of Data Preprocessing:**\n",
    "\n",
    "*   **Loading the MNIST dataset:** `mnist.load_data()` loads the MNIST dataset, which is already split into training and testing sets (`(x_train, y_train), (x_test, y_test)`). `x_train` and `x_test` contain the images (pixel data), and `y_train` and `y_test` contain the corresponding labels (digits 0-9).\n",
    "*   **Normalization:** `x_train = x_train.astype(\"float32\") / 255.0` and `x_test = x_test.astype(\"float32\") / 255.0` normalize the pixel values.  Pixel values in images are typically in the range 0-255. Dividing by 255 scales them to the range 0-1. This normalization helps the neural network train faster and more effectively.\n",
    "*   **Adding Channel Dimension:** `x_train = x_train.reshape(-1, 28, 28, 1)` and `x_test = x_test.reshape(-1, 28, 28, 1)` reshape the data to add a channel dimension.  Even though MNIST images are grayscale (single channel), CNNs in Keras expect input data to have a channel dimension.  We reshape from `(number_of_images, 28, 28)` to `(number_of_images, 28, 28, 1)`. The `-1` in `reshape` means \"infer the dimension based on the size of the array.\"\n",
    "*   **One-Hot Encoding:** `y_train = to_categorical(y_train, num_classes)` and `y_test = to_categorical(y_test, num_classes)` perform one-hot encoding on the labels.  Instead of representing the digit '3' as a single number, one-hot encoding converts it into a vector `[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]`, where the 4th position (index 3) is 'hot' (value 1), and all other positions are 'cold' (value 0). This is a standard way to represent categorical labels for neural networks in multi-class classification problems. `num_classes = 10` specifies that we have 10 classes (digits 0-9).\n",
    "\n",
    "## Section 3: Model Definition - Building the CNN\n",
    "\n",
    "Now we will define the architecture of our Convolutional Neural Network (CNN).  You will be building a sequential model using Keras layers.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1.  **Carefully examine the code in the cell below.** Notice the structure of the `keras.Sequential` model.\n",
    "2.  **Fill in the missing parts** marked with `# Students: Fill in the blanks` to complete the model definition.\n",
    "3.  **Experiment!** You are encouraged to try different configurations for the layers, such as changing the number of filters in the convolutional layers, or adding more layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FFOe2fviyabM"
   },
   "outputs": [],
   "source": [
    "# Cell 3: Model Definition\n",
    "# Build the CNN model.  Students: Fill in the missing parts!\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(28, 28, 1)),  # Input layer\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"), # Convolutional layer 1\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)), # Max pooling layer 1\n",
    "        # Students: Add another Conv2D layer here.  Experiment with the number of filters!\n",
    "        # layers.Conv2D(____, kernel_size=(____, ____), activation=\"____\"),  # Convolutional layer 2\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"), # Convolutional layer 2\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)), # Max pooling layer 2\n",
    "        # Students: Add another MaxPooling2D layer here if needed.\n",
    "        # layers.MaxPooling2D(pool_size=(____, ____)),  # Max pooling layer 2\n",
    "        layers.Flatten(),  # Flatten layer\n",
    "        layers.Dropout(0.5),  # Dropout layer\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),  # Output layer\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-x0iiCewyabM"
   },
   "source": [
    "**Explanation of Layers:**\n",
    "\n",
    "*   **`keras.Input(shape=(28, 28, 1))`:** This is the input layer of our model. It specifies the shape of the input images, which are 28x28 pixels with 1 channel (grayscale).\n",
    "*   **`layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\")`:** This is a 2D Convolutional layer.\n",
    "    *   `32`: This is the number of filters (also called kernels). Each filter learns to detect specific features in the input image.\n",
    "    *   `kernel_size=(3, 3)`: This defines the size of the convolutional filter as 3x3 pixels.\n",
    "    *   `activation=\"relu\"`:  ReLU (Rectified Linear Unit) is the activation function. It introduces non-linearity into the model, allowing it to learn complex patterns.\n",
    "*   **`layers.MaxPooling2D(pool_size=(2, 2))`:** This is a Max Pooling layer.\n",
    "    *   `pool_size=(2, 2)`:  It reduces the spatial dimensions of the feature maps by taking the maximum value within each 2x2 window. This helps to reduce the number of parameters, control overfitting, and make the model more robust to small shifts and distortions in the input.\n",
    "*   **`layers.Flatten()`:** This layer flattens the 2D feature maps from the convolutional and pooling layers into a 1D vector. This is necessary to connect the convolutional part of the network to the fully connected (Dense) layers.\n",
    "*   **`layers.Dropout(0.5)`:** This is a Dropout layer.\n",
    "    *   `0.5`: This sets the dropout rate to 50%. During training, this layer randomly sets 50% of the input units to 0 at each update. This is a regularization technique that helps to prevent overfitting.\n",
    "*   **`layers.Dense(num_classes, activation=\"softmax\")`:** This is the output Dense (fully connected) layer.\n",
    "    *   `num_classes`:  This is set to 10 because we have 10 classes (digits 0-9).\n",
    "    *   `activation=\"softmax\"`: Softmax activation ensures that the output values are probabilities, and they sum up to 1 across all classes.  The output will be a vector of 10 probabilities, where each probability represents the model's confidence that the input image belongs to that specific digit class.\n",
    "\n",
    "## Section 4: Model Compilation - Choosing Loss and Optimizer\n",
    "\n",
    "Before we can train our model, we need to compile it.  Compilation involves choosing an optimizer, a loss function, and metrics to evaluate the model's performance.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1.  **Examine the code cell below.** You need to fill in the blanks for the `loss` and `optimizer` parameters in `model.compile()`.\n",
    "2.  **Choose an appropriate loss function and optimizer** for this multi-class classification problem.\n",
    "3.  **In the Markdown cell after the code, explain your choices.** Why are these choices suitable for this task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YVr-ooXfyabM"
   },
   "outputs": [],
   "source": [
    "# Cell 4: Model Compilation\n",
    "# Students: Choose an appropriate loss function and optimizer.  Why did you choose these?\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]) #Students: Fill in the blanks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2R7iy69RyabN"
   },
   "source": [
    "**Explanation of Choices (To be filled by students in the reflection section):**\n",
    "\n",
    "*   **Loss Function:** You need to choose a loss function that is appropriate for multi-class classification. Think about what kind of error we are trying to minimize when classifying digits into 10 categories.\n",
    "*   **Optimizer:** You need to choose an optimizer that will efficiently update the model's weights to minimize the loss function.  Consider common optimizers used in deep learning.\n",
    "*   **Metrics:** We are using \"accuracy\" as a metric to evaluate the model's performance. Accuracy is a common metric for classification tasks, representing the percentage of correctly classified images.\n",
    "\n",
    "<span style=\"color: blue;\">**My Explanation:**</span>\n",
    "\n",
    "**Loss Function (Categorical Crossentropy):**\n",
    "It directly measures how well the model’s predicted probabilities align with the one-hot-encoded true labels across multiple classes. It penalizes large deviations, guiding the weights to minimize classification error effectively for a multi-class problem like MNIST.\n",
    "\n",
    "**Optimizer (Adam):**\n",
    "Adam is a popular choice because it adaptively adjusts the learning rate for each parameter, offering faster convergence and efficient weight updates. It combines the benefits of both AdaGrad and RMSProp, making it well-suited for various deep learning tasks.\n",
    "\n",
    "**Metrics (Accuracy):**\n",
    "Accuracy provides a straightforward measure of how many predictions match the true labels. It’s a clear indicator of performance when each class is equally important, making it a natural choice for error quantification in digit classification scenarios.\n",
    "\n",
    "\n",
    "\n",
    "## Section 5: Model Training - Fitting the Model to the Data\n",
    "\n",
    "Now it's time to train our CNN model using the training data. Training involves feeding the training data to the model and adjusting its weights to minimize the loss function.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1.  **Examine the code cell below.** You need to fill in the blanks for `batch_size` and `epochs` in `model.fit()`.\n",
    "2.  **Choose appropriate values for `batch_size` and `epochs`.**\n",
    "3.  **Run the code cell to start training.** Observe the training progress, especially the loss and accuracy on both the training and validation sets.\n",
    "4.  **Experiment!** Change the `batch_size` and `epochs` and see how it affects the training process and the final performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UtpZIbTHyabN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.7772 - loss: 0.7498 - val_accuracy: 0.9757 - val_loss: 0.0874\n",
      "Epoch 2/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9599 - loss: 0.1281 - val_accuracy: 0.9827 - val_loss: 0.0611\n",
      "Epoch 3/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9719 - loss: 0.0894 - val_accuracy: 0.9862 - val_loss: 0.0483\n",
      "Epoch 4/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9775 - loss: 0.0728 - val_accuracy: 0.9885 - val_loss: 0.0419\n",
      "Epoch 5/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9810 - loss: 0.0610 - val_accuracy: 0.9897 - val_loss: 0.0374\n",
      "Epoch 6/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9830 - loss: 0.0553 - val_accuracy: 0.9905 - val_loss: 0.0356\n",
      "Epoch 7/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9852 - loss: 0.0487 - val_accuracy: 0.9902 - val_loss: 0.0381\n",
      "Epoch 8/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9856 - loss: 0.0464 - val_accuracy: 0.9922 - val_loss: 0.0321\n",
      "Epoch 9/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9857 - loss: 0.0431 - val_accuracy: 0.9915 - val_loss: 0.0335\n",
      "Epoch 10/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9866 - loss: 0.0415 - val_accuracy: 0.9923 - val_loss: 0.0311\n",
      "Epoch 11/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9875 - loss: 0.0411 - val_accuracy: 0.9903 - val_loss: 0.0332\n",
      "Epoch 12/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.9878 - loss: 0.0394 - val_accuracy: 0.9922 - val_loss: 0.0309\n",
      "Epoch 13/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9880 - loss: 0.0360 - val_accuracy: 0.9918 - val_loss: 0.0300\n",
      "Epoch 14/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9890 - loss: 0.0332 - val_accuracy: 0.9918 - val_loss: 0.0288\n",
      "Epoch 15/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9893 - loss: 0.0338 - val_accuracy: 0.9915 - val_loss: 0.0313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x273573c5bd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 5: Model Training\n",
    "# Students: Adjust the batch size and number of epochs.  What happens if you change them?\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=15, validation_split=0.1) #Students: Fill in the blanks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FW7k1KMyabN"
   },
   "source": [
    "**Explanation of Training Parameters:**\n",
    "\n",
    "*   **`batch_size`:** This determines the number of training samples processed in each mini-batch during training. A larger batch size can speed up training but might require more memory. A smaller batch size can lead to more noisy updates but might generalize better.\n",
    "*   **`epochs`:**  One epoch represents one complete pass through the entire training dataset.  More epochs can potentially lead to better training but also increase the risk of overfitting, where the model learns the training data too well and performs poorly on unseen data.\n",
    "*   **`validation_split=0.1`:**  This reserves 10% of the training data as a validation set. During training, the model's performance is evaluated on this validation set after each epoch. This helps to monitor for overfitting and tune hyperparameters.\n",
    "\n",
    "<span style=\"color: blue;\">**My Explanation:**</span>\n",
    "\n",
    "**Batch Size (128):**\n",
    "Processes the training samples in sets of a fixed size. Larger batch sizes can make training faster but need more memory, while smaller batch sizes might help the model generalize more effectively but can increase training time.\n",
    "\n",
    "Epochs (15):\n",
    "Specifies how many times the model passes through the entire training data. More epochs allow the model to refine its parameters further but also raise the possibility of overfitting if taken too far.\n",
    "\n",
    "Validation Split (0.1):\n",
    "Reserves a fraction of the training data (10% in this case) for validation. The model is evaluated on this set after each epoch, helping detect overfitting and assess improvement during training.\n",
    "\n",
    "Observing the output, we can see that the accuracy and loss improve steadily over 15 epochs, indicating that the chosen parameters offer a good balance between training time and performance.\n",
    "\n",
    "## Section 6: Model Evaluation - Assessing Performance on Test Data\n",
    "\n",
    "After training, we need to evaluate our model's performance on the test dataset.  This gives us an estimate of how well the model generalizes to unseen data.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1.  **Run the code cell below.**\n",
    "2.  **Observe the output.**  It will print the test loss and test accuracy.\n",
    "3.  **Think about the results.** Is the test accuracy satisfactory?  How does it compare to the training and validation accuracy you observed during training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "f3KehXAlyabO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0259\n",
      "Test accuracy: 0.9908\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Model Evaluation\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Test loss: {loss:.4f}\")\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue;\">**My Explanation:**</span>\n",
    "\n",
    "The model correctly classifies about 99.08% of test images, indicating strong generalization. The low loss value (0.0259) suggests the model’s predictions closely match the true labels, further confirming its high performance on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VL_6FT9K5bBr"
   },
   "source": [
    "## Section 7: Reflection and Answers to Questions\n",
    "This is an important section! Take some time to reflect on what you have learned and answer the following questions in detail. Your thoughtful answers will demonstrate your understanding of the concepts covered in this assignment.\n",
    "\n",
    "**Reflection Questions:**\n",
    "\n",
    "1.  **Conv2D Layer:** What is the role of the Conv2D layer? How do the `kernel_size` and the number of filters affect the learning process? *Hint: Experiment by changing these values in Cell 3.*\n",
    "\n",
    "> <span style=\"color: blue;\">**My Answer:**</span>\n",
    ">\n",
    "> The Conv2D layer applies filters (kernels) across the input image to detect features such as edges or textures. The kernel_size determines how large these filters are (e.g., 3×3), influencing the granularity of captured features. A larger kernel may capture more global patterns at the risk of losing some detail, while a smaller kernel focuses on local features. Increasing the number of filters allows the model to learn a broader set of features, but it also increases computational cost and the risk of overfitting.\n",
    "\n",
    "2.  **MaxPooling2D Layer:** What is the purpose of the MaxPooling2D layer? How does it contribute to the model's performance?  *Hint:  Try removing or adding a MaxPooling2D layer and see what happens.*\n",
    "\n",
    "> <span style=\"color: blue;\">**My Answer:**</span>\n",
    ">\n",
    "> MaxPooling2D reduces the spatial dimensions of feature maps, keeping only the most prominent signal within each pool region. This downsampling leads to fewer parameters, speeding up training and helping to generalize by ignoring minor variations. Removing MaxPooling can make the model larger and more prone to overfitting, whereas adding too many pooling operations might cause it to lose valuable spatial information.\n",
    "\n",
    "3.  **One-Hot Encoding:** Why do we use one-hot encoding for the labels?\n",
    "\n",
    "> <span style=\"color: blue;\">**My Answer:**</span>\n",
    ">\n",
    "> One-hot encoding transforms the labels into a vector format where only the index of the correct class is set to 1, and the rest are 0. This format aligns with the multi-class classification output of the model, ensuring that the network’s final layer can compare predicted probabilities with actual classes correctly.\n",
    "\n",
    "4.  **Flatten Layer:** Why do we need the Flatten layer before the Dense layer?\n",
    "\n",
    "> <span style=\"color: blue;\">**My Answer:**</span>\n",
    ">\n",
    "> After the convolutional and pooling layers, the data is still in a structured 2D format. Flatten converts this 2D feature map into a 1D vector, enabling a Dense (fully connected) layer to process these features as standard input for classification.\n",
    "\n",
    "5.  **Optimizer and Loss Function:** What optimizer and loss function did you choose in Cell 4? Explain your choices.  Why is categorical cross-entropy a suitable loss function for this task?  Why is Adam a good choice of optimiser?\n",
    "\n",
    "> <span style=\"color: blue;\">**My Answer:**</span>\n",
    ">\n",
    "> A common pairing is the Adam optimizer with the categorical cross-entropy loss.\n",
    ">\n",
    "> - Categorical Cross-Entropy: Measures how close the model’s predicted probability distribution is to the one-hot target distribution. This is a natural fit for multi-class problems like digit classification.\n",
    ">\n",
    "> - Adam: Combines the advantages of AdaGrad and RMSProp, adaptively adjusting the learning rate for each parameter. It converges quickly and handles a wide range of problems effectively.\n",
    "\n",
    "\n",
    "6.  **Batch Size and Epochs:** How did you choose the batch size and number of epochs in Cell 5? What are the effects of changing these parameters?  *Hint:  Experiment!*\n",
    "\n",
    "> <span style=\"color: blue;\">**My Answer:**</span> \n",
    ">\n",
    "> Batch size (e.g., 128) controls how many samples the model sees before updating weights. Larger batches can speed up each epoch but might require more memory. Fewer epochs might prevent overfitting but could undertrain the model, while too many epochs risk overfitting. Tuning these parameters often involves trial and error, guided by observing training and validation performance.\n",
    "\n",
    "7.  **Dropout:**  Why is the Dropout layer included in the model?\n",
    "\n",
    "> <span style=\"color: blue;\">**My Answer:**</span> \n",
    ">\n",
    "> The Dropout layer randomly zeroes out a fraction of the neurons during training, helping to prevent overfitting by reducing the network’s dependency on specific neurons. This introduces some regularization, making the network more robust and improving generalization.\n",
    "\n",
    "8.  **Model Architecture:**  Describe the overall architecture of your CNN. How many convolutional layers did you use?  How many max pooling layers?  What is the final dense layer doing?\n",
    "\n",
    "> <span style=\"color: blue;\">**My Answer:**</span>\n",
    ">\n",
    "> A typical structure might be two or three Conv2D layers interspersed with MaxPooling2D, followed by a Flatten layer and one or two Dense layers. The final Dense layer produces class probabilities for digits 0–9. This progression captures spatial features early and gradually moves toward class-level decisions.\n",
    "\n",
    "9.  **Performance:** What accuracy did you achieve on the test set?  Are you happy with the result? Why or why not?  If you're not happy, what could you try to improve the performance?\n",
    "\n",
    "> <span style=\"color: blue;\">**My Answer:**</span> \n",
    ">\n",
    "> If the model achieves around 99% accuracy on the test set, that indicates strong discrimination of handwritten digits. This result is typically considered satisfactory for MNIST. If improvement is desired, strategies include adjusting hyperparameters (e.g., more filters or epochs), adding dropout layers, or experimenting with data augmentation to boost generalization.\n",
    "\n",
    "**Tips and Explanations:**\n",
    "\n",
    "*   **Normalization:**  Dividing the pixel values by 255 normalizes them to the range [0, 1]. This is important for training neural networks.\n",
    "\n",
    "*   **Reshaping:**  The `reshape` operation adds a channel dimension to the images.  For grayscale images, the channel dimension is 1.\n",
    "\n",
    "*   **One-Hot Encoding:** `to_categorical` converts the class labels (0-9) into one-hot encoded vectors.\n",
    "\n",
    "*   **Conv2D Parameters:** The `kernel_size` determines the size of the convolutional filter (e.g., 3x3). The number of filters determines how many different features are learned.\n",
    "\n",
    "*   **MaxPooling2D Parameters:** The `pool_size` determines the size of the pooling window (e.g., 2x2).\n",
    "\n",
    "*   **Optimizer:** The optimizer is the algorithm used to update the model's weights during training.\n",
    "\n",
    "*   **Loss Function:** The loss function measures the error between the model's predictions and the true labels.\n",
    "\n",
    "*   **Batch Size:** The batch size is the number of samples processed in each training iteration.\n",
    "\n",
    "*   **Epochs:** An epoch is one complete pass through the entire training dataset.\n",
    "\n",
    "*   **Dropout:** Dropout is a regularization technique that helps prevent overfitting.\n",
    "\n",
    "Remember to run each cell to see its output.  Experiment with the code and try to understand how different parameters affect the model's performance.  Good luck!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9_VbuuK6MFg"
   },
   "source": [
    "# Conclusion and Submission\n",
    " Congratulations on completing this notebook assignment! You have successfully built and trained a Convolutional Neural\n",
    " Network to classify handwritten digits from the MNIST dataset. You've explored key concepts like convolutional layers, pooling layers, activation functions, optimizers, loss functions, and training procedures. To further solidify your understanding, consider the following:\n",
    "*   **Review your notebook:** Go back through each section, reread the explanations, and make sure you understand the code and the concepts.\n",
    "*   **Experiment further:** Try different CNN architectures, add more layers, change hyperparameters, and see how it affects the performance. Explore other optimizers or loss functions.\n",
    "*   **Reflect on your learning:**  Think about the challenges you faced and how you overcame them. What were the most important takeaways for you from this assignment?\n",
    "\n",
    "**Submission Instructions**\n",
    "\n",
    "To submit your assignment:\n",
    "\n",
    "1.  **Save your notebook:** Ensure all your work, including code cells, outputs, and answers to reflection questions, is saved in the notebook.\n",
    "2.  **Print the notebook as a `.pdf` file** and submit it to Canvas.\n",
    "\n",
    "**Deadline:** February, 12th"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
